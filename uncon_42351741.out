--- Initializing Conda ---
Conda executable: Usage: /usr/bin/which [-a] args
Conda environments visible to this job:

# conda environments:
#
                       /hpc/group/datap2023ecbc/sm996/miniconda3
                       /hpc/group/datap2023ecbc/sm996/miniconda3/envs/amp
                       /hpc/group/datap2023ecbc/sm996/miniconda3/envs/pytorch-env
base                 * /hpc/group/naderilab/sm996/miniconda3
foldseek_env           /hpc/group/naderilab/sm996/miniconda3/envs/foldseek_env
geo_project            /hpc/group/naderilab/sm996/miniconda3/envs/geo_project

--------------------------
--- Running Python Script ---
PyTorch version: 2.9.0+cu128
Transformers version: 4.57.1
Using device: cuda
Loading model...
Gradient checkpointing enabled
Trainable parameters: 343,520 (4.38% of total)
Structure alignment loss ENABLED - will use structural embeddings
================================================================================
Using simple structural encoder (fallback, not GearNet)
Reason: TorchDrug GearNet hanging issue (see TORCHDRUG_ISSUE.md)
To switch back to GearNet: set use_simple_encoder=False after fixing TorchDrug
================================================================================
Created SimpleStructuralEncoder with hidden_dim=320
  Parameters: 318,720
Embedding cache initialized at: outputs/embedding_cache
Embedding cache initialized at: outputs/embedding_cache
Embeddings will be generated on-the-fly in first epoch and cached to disk for subsequent epochs
Loading dataset...
Using efficient pre-processed dataset...
Structural tokens available: True
Pre-computed embeddings not available, will generate on-the-fly with hidden_dim=320
Loaded and cached 180365 proteins.
Loaded and cached structural tokens for 180359 proteins.
Dataset split: 144292 training samples, 36073 validation samples
Using separate learning rates: primal_lr=0.001, dual_lr=0.5
Mixed precision training enabled
Starting training for 50 epochs...
Effective batch size: 64

Epoch 1/50
