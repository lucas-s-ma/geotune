Using device: cuda
Using stub implementation for pre-trained GNN (avoiding TorchDrug)
Loaded structural tokens for 11157 proteins
Loaded 11158 proteins from pre-processed dataset
Dataset split: 8926 training, 2232 validation samples.
Starting constrained training for 10 epochs...

--- Epoch 1/10 ---
Epoch 1 Summary:
  Train | Lagrangian: 2.3196, MLM: 2.1193, Dihedral: 0.9759, GNN: 6.2363, Foldseek: 3.0542
  Val   | MLM: 1.2578, Dihedral: 0.7666, GNN: 5.9575, Foldseek: 3.0565

--- Epoch 2/10 ---
Epoch 2 Summary:
  Train | Lagrangian: 1.3378, MLM: 1.1848, Dihedral: 0.6672, GNN: 5.8734, Foldseek: 3.0519
  Val   | MLM: 1.1359, Dihedral: 0.6167, GNN: 5.8704, Foldseek: 3.0530

--- Epoch 3/10 ---
Epoch 3 Summary:
  Train | Lagrangian: 1.2633, MLM: 1.1168, Dihedral: 0.5797, GNN: 5.8299, Foldseek: 3.0487
  Val   | MLM: 1.0866, Dihedral: 0.5669, GNN: 5.8440, Foldseek: 3.0501

--- Epoch 4/10 ---
Epoch 4 Summary:
  Train | Lagrangian: 1.2223, MLM: 1.0761, Dihedral: 0.5489, GNN: 5.8069, Foldseek: 3.0463
  Val   | MLM: 1.0668, Dihedral: 0.5456, GNN: 5.8242, Foldseek: 3.0481

--- Epoch 5/10 ---
Epoch 5 Summary:
  Train | Lagrangian: 1.1972, MLM: 1.0497, Dihedral: 0.5319, GNN: 5.7935, Foldseek: 3.0446
  Val   | MLM: 1.0434, Dihedral: 0.5329, GNN: 5.8142, Foldseek: 3.0471

--- Epoch 6/10 ---
Epoch 6 Summary:
  Train | Lagrangian: 1.1821, MLM: 1.0328, Dihedral: 0.5194, GNN: 5.7798, Foldseek: 3.0434
  Val   | MLM: 1.0212, Dihedral: 0.5252, GNN: 5.8010, Foldseek: 3.0458

--- Epoch 7/10 ---
Epoch 7 Summary:
  Train | Lagrangian: 1.1653, MLM: 1.0132, Dihedral: 0.5130, GNN: 5.7730, Foldseek: 3.0423
  Val   | MLM: 1.0161, Dihedral: 0.5196, GNN: 5.7923, Foldseek: 3.0450

--- Epoch 8/10 ---
Epoch 8 Summary:
  Train | Lagrangian: 1.1665, MLM: 1.0116, Dihedral: 0.5072, GNN: 5.7662, Foldseek: 3.0416
  Val   | MLM: 1.0073, Dihedral: 0.5142, GNN: 5.7844, Foldseek: 3.0444

--- Epoch 9/10 ---
Epoch 9 Summary:
  Train | Lagrangian: 1.1594, MLM: 1.0015, Dihedral: 0.5041, GNN: 5.7603, Foldseek: 3.0411
  Val   | MLM: 1.0004, Dihedral: 0.5113, GNN: 5.7826, Foldseek: 3.0440

--- Epoch 10/10 ---
Epoch 10 Summary:
  Train | Lagrangian: 1.1603, MLM: 0.9985, Dihedral: 0.5023, GNN: 5.7594, Foldseek: 3.0409
  Val   | MLM: 0.9972, Dihedral: 0.5103, GNN: 5.7806, Foldseek: 3.0438
Final LoRA adapters saved to outputs/final_model
Logged final lambda histograms to wandb.

Training completed!
